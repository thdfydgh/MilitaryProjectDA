{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Project]  기계 시설물 센서 데이터 기반 고장 예지 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목적\n",
    "  - 도시철도 역사 3개소 용량(kW)별 12종 전동기 41대의 센서데이터를 활용하여 고장의 주요 유형을 예측합니다.\n",
    "  - 파이선 머신러닝 라이브러리인 scikit-learn (SKLearn) 을 활용하여 센서의 수집 신호를 학습하여 고장의 유형 (베어링 불량. 회전체 불평형, 축정렬 불량, 벨트 느슨함)을 예측하는 모델을 개발합니다. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lab2의 목표\n",
    "- 이번 lab에서는 앞서 생성한 hdf5를 로딩하고, SVM algorithm을 적용하여 성능을 평개해 보고 예측을 수행해 보겠습니다.\n",
    "\n",
    "- SVM의 성능을 개선하는 몇가지 방법을 실습해 봅니다.\n",
    "- Decision Tree, Random Forest에 대해서도 실습해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 머신러닝 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 학습 데이터 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프로젝트에 필요한 라이브러리를 미리 import 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lab1 에서 생성한 dataset.h5를 pandas dataframe으로 읽어 보도록 하겠습니다.\n",
    "- Xs는 예측에 입력으로 사용할 데이터 이며, Ys는 레이블입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_AbsMax   S_AbsMax   T_AbsMax  R_AbsMean  S_AbsMean  T_AbsMean  \\\n",
      "0      3.523438   3.203125   4.204102   2.123972   1.904358   2.313897   \n",
      "1      4.684570   4.964844   4.924805   2.581198   2.669424   2.562180   \n",
      "2      4.764648   5.325195   4.964844   2.787059   3.010797   2.761754   \n",
      "3      4.829712   5.069946   4.994873   2.682742   2.741545   2.638449   \n",
      "4     81.649658  81.629639  81.629639  54.699525  54.174483  54.228436   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2329   4.674561   4.994873   4.754639   2.658974   2.775588   2.589056   \n",
      "2330   5.044922   5.165039   4.964844   2.594071   2.685360   2.562720   \n",
      "2331   3.483398   3.203125   4.244141   2.092722   1.873928   2.290134   \n",
      "2332  79.922974  79.592651  80.243286  47.443321  46.707518  46.859366   \n",
      "2333   4.469360   4.829712   4.429321   2.673493   2.785202   2.553396   \n",
      "\n",
      "           R_P2P       S_P2P       T_P2P      R_RMS  ...        R_2x  \\\n",
      "0       7.046875    6.326172    7.927734   2.372161  ...    3.498032   \n",
      "1       9.168945    9.609375    9.529297   2.889765  ...    4.114982   \n",
      "2       8.968750   10.330078    9.289062   3.091519  ...    0.232917   \n",
      "3       9.369141    9.889648    9.734497   3.006779  ...    4.358700   \n",
      "4     163.279297  163.239258  163.199219  60.079840  ...  126.112648   \n",
      "...          ...         ...         ...        ...  ...         ...   \n",
      "2329    9.128906    9.729492    9.249023   2.980832  ...    4.297484   \n",
      "2330    9.689453   10.209961    9.769531   2.899138  ...    4.223995   \n",
      "2331    6.926758    6.286133    7.927734   2.338594  ...    3.402179   \n",
      "2332  157.793945  157.353516  157.713867  52.553387  ...    7.444110   \n",
      "2333    8.648438    9.449219    8.648438   2.978900  ...    4.497202   \n",
      "\n",
      "            S_2x        T_2x      R_3x      S_3x      T_3x      R_4x  \\\n",
      "0       3.179915    3.814222  0.017591  0.014421  0.017169  0.034466   \n",
      "1       4.289073    4.136721  0.117036  0.115290  0.110776  0.011292   \n",
      "2       0.245827    0.237814  0.038987  0.041477  0.043595  0.163615   \n",
      "3       4.483748    4.341036  0.138768  0.138278  0.134083  0.052063   \n",
      "4     124.803014  124.824012  2.425170  3.301954  3.143019  1.103665   \n",
      "...          ...         ...       ...       ...       ...       ...   \n",
      "2329    4.517970    4.235772  0.141650  0.142962  0.137971  0.013040   \n",
      "2330    4.400142    4.210039  0.109691  0.110948  0.102688  0.023522   \n",
      "2331    3.092922    3.730233  0.017172  0.013965  0.018536  0.021099   \n",
      "2332    6.832184    7.538282  1.640813  0.941839  1.530674  0.916591   \n",
      "2333    4.720470    4.342585  0.126487  0.123981  0.120994  0.014008   \n",
      "\n",
      "          S_4x      T_4x  WATT  \n",
      "0     0.030679  0.027279   2.2  \n",
      "1     0.014993  0.011967   2.2  \n",
      "2     0.168936  0.164779   2.2  \n",
      "3     0.056198  0.052608   2.2  \n",
      "4     1.692871  2.021573  55.0  \n",
      "...        ...       ...   ...  \n",
      "2329  0.013348  0.012445   2.2  \n",
      "2330  0.015858  0.011416   2.2  \n",
      "2331  0.020938  0.022594   2.2  \n",
      "2332  0.364655  0.788922  55.0  \n",
      "2333  0.016017  0.015919   2.2  \n",
      "\n",
      "[2334 rows x 46 columns]       0\n",
      "0     3\n",
      "1     0\n",
      "2     0\n",
      "3     2\n",
      "4     4\n",
      "...  ..\n",
      "2329  2\n",
      "2330  0\n",
      "2331  3\n",
      "2332  0\n",
      "2333  2\n",
      "\n",
      "[2334 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Xs = pd.read_hdf('./dataset.h5', 'Xs')\n",
    "Ys = pd.read_hdf('./dataset.h5', 'Ys')\n",
    "print(Xs, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine Learning을 학습할 데이터는 Traning Set, Validation set, Test set 으로 나눠야 합니다.\n",
    "\n",
    "- Traning Set은 모델의 파라메터를 학습하기 위해서 사용합니다.\n",
    "\n",
    "- Validation Set 과 Test Set 은 학습한 모델을 평가하기 위해서 사용합니다.\n",
    "\n",
    "- Validation Set 은 모델을 반복적으로 학습하는 과정에서 지속적으로 사용하면서 학습한 모델의 상태를 모니터링하기 위해서 사용하며 Test Set 은 학습이 완료된 시점에서 모델의 최종 성능을 판별하기 위한 목적으로 사용합니다.\n",
    "\n",
    "- Traning set과 Test Set은 모델의 학습과 성능평가를 위해서 필수적으로 나누어야 합니다.\n",
    "\n",
    "- 이번 Lab에서는 Validation Set은 사용하지 않습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 데이터 셋을 Training Set 과 Test Set으로  각각 80%, 20%의 비율로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1867, 46) (1867, 1) (467, 46) (467, 1)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_tr, X_te, Y_tr, Y_te = train_test_split(Xs.values, Ys.values, test_size=test_size, random_state=seed)\n",
    "print(X_tr.shape, Y_tr.shape, X_te.shape, Y_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scikit-learn 라이브러리는 데이터분석 및 기계학습을 쉽게 할 수 있도록 도와주는 라이브러리 입니다.\n",
    "\n",
    "- Sckkit-learn의 ML 알고리즘은 사용할  algorithm과 그에 필요한 파라메터를 정의하는 모델 생성 단계, fit함수를 이용한 학습단계로 구성되며, 학습된 모델의 성능을 확인할 수 있는 다양한 함수를 제공합니다.\n",
    "\n",
    "\n",
    "- SVM은 Margin을 최대화하는 Decisoion Boundary(결정경계)를 찾는 지도학습 (Supervised Learning) 알고리즘 입니다.\n",
    "- Margin은 결정경계에서 가장 가까운 각 class의 data point의 거리로 입니다.\n",
    "\n",
    "\n",
    "- 먼저 SVM 모델을 학습하고 성능을 평가하겠습니다.\n",
    "- SVM은 One-vs-One Multi-class Classification을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.5420460632029994\n",
      "Accuracy of svm.SVC classifier on test set: 0.5246252676659529\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "clf = svm.SVC(decision_function_shape='ovo', random_state=seed)\n",
    "\n",
    "#모델 학습\n",
    "clf.fit(X_tr, Y_tr.ravel())\n",
    "\n",
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {clf.score(X_tr, Y_tr)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {clf.score(X_te, Y_te)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM의 테스트셋 평가 결과가 0.5정도로 낮은 편입니다. \n",
    "- 정답 레이블의 분포 비율이 매우 다르기 때문에 정확도만으로 판단하기는 어렵습니다.\n",
    "\n",
    "\n",
    "- predict 함수는 학습된 모델을 이용하여 예측을 수행하는 함수 입니다.\n",
    "\n",
    "\n",
    "-  classificatuion report는 predict 함수를 통해서 예측한 class와 정답 label을 가지고 class별로 성능이 어떤지 확인할 수 있습니다.\n",
    "- Confusion Matrix를 이용하여 어떤 class를 어떻게 예측하였는지 구체적으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.89      0.63       212\n",
      "           2       0.54      0.38      0.44        69\n",
      "           4       0.97      0.42      0.58        72\n",
      "\n",
      "   micro avg       0.52      0.69      0.60       353\n",
      "   macro avg       0.67      0.56      0.55       353\n",
      "weighted avg       0.60      0.69      0.58       353\n",
      "\n",
      "confusion matrix:\n",
      " [[189   0  22   0   1]\n",
      " [ 42   0   0   0   0]\n",
      " [ 43   0  26   0   0]\n",
      " [ 72   0   0   0   0]\n",
      " [ 42   0   0   0  30]]\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델을 가지고 예측을 수행합니다.\n",
    "y_pred = clf.predict(X_te)\n",
    "\n",
    "#예측한 결과와 정답 label을 이용하여 classification report와 confusion matrix를 출력해 봅니다.\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion matrix는 정답 라벨을 y축으로 하고, 예측한 class 를 x 축으로 하여 예측한 값과 실제 값을 비교한 표입니다.\n",
    "- 세 번째 row인 (43, 0, 26, 0, 0)의 의미는 실제 라벨이 2인 (0부터 시작합니다)인 클래스를 0으로 43개를 예측하였고, 3으로 26개를 예측하였다는 의미 입니다.\n",
    "- Confusion matrix를 보면 class 1 과 3을 잘 예측하지 못한 결과를 확인 할 수 있습니다.\n",
    "- 또한, 대부분의 class를 0으로 예측하는 것을 알 수 있습니다.\n",
    "\n",
    "\n",
    "- 정상(0)인 샘플이 많은 unbalanced Dataset에서는 class weight를 사용하면 효과가 있을 수 있습니다.\n",
    "- class_weight='balanced'로 하여 학습을 하고 결과를 검토해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.3797536154258168\n",
      "Accuracy of svm.SVC classifier on test set: 0.37044967880085655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       212\n",
      "           1       0.18      1.00      0.30        42\n",
      "           2       0.46      0.38      0.42        69\n",
      "           3       0.52      1.00      0.68        72\n",
      "           4       0.97      0.42      0.58        72\n",
      "\n",
      "    accuracy                           0.37       467\n",
      "   macro avg       0.63      0.56      0.40       467\n",
      "weighted avg       0.77      0.37      0.30       467\n",
      "\n",
      "confusion matrix:\n",
      " [[  3 153  30  25   1]\n",
      " [  0  42   0   0   0]\n",
      " [  0  43  26   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  0   0   0  42  30]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "clf = svm.SVC(decision_function_shape='ovo', class_weight='balanced', random_state=seed)\n",
    "\n",
    "#모델 학습\n",
    "clf.fit(X_tr, Y_tr.ravel())\n",
    "\n",
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {clf.score(X_tr, Y_tr)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {clf.score(X_te, Y_te)}')\n",
    "# 학습된 모델을 가지고 예측을 수행합니다.\n",
    "y_pred = clf.predict(X_te)\n",
    "\n",
    "#예측한 결과와 정답 label을 이용하여 classification report와 confusion matrix를 출력해 봅니다.\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy가 54%에서 38% 정도로 떨어 졌지만 Confusion matrix를 보면 label이 0이 아닌 class를 더 잘 맞추는 것을 확인 할 수 있습니다.\n",
    "\n",
    "- 정상(0)이 96%이고, 4가지 형태의 불량이 각각 1%인 데이터 셋이 있다면 무조건 0으로 예측하는 모델은 96%의 accuracy를 보입니다.\n",
    "\n",
    "- 무조건 정상으로만 예측하는 모델과 50%의 확률로 4가지 형태의 불량을 예측하는 모델이 있다면, 후자의 모델이 더 유용한 모델인 것은 직관적으로 당연할 것입니다.\n",
    "\n",
    "- Accuracy가 모델의 성능을 평가하는 대표적인 지표이지만, class의 분포가 일정하지 않은 데이터 셋의 경우에는 그렇지 않을 경우도 있습니다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 데이터 정규화를 위한 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터에서 어떤 feature는 0에서 1까지의 값을 가지는데, 다른 feature는 100에서 1,000까지의 값을 가진다면, 100~1,000까지의 값을 가지는 feature가 특정 알고리즘에서는 더 큰 영향을 미치는 경우가 있습니다.\n",
    "\n",
    "- 따라서 데이터를 정규화(Normalization) 혹은 표준화(Standardization)를 수행하여 모든 Feature의 scale을 동일하게 맞추어 줄 필요가 있습니다.\n",
    "\n",
    "\n",
    "- 전처리 알고리즘을 Sklearn에서는 파이프라인으로 추가할 수 있습니다.\n",
    "\n",
    "- StandardScalar는 데이터에서 평균과 표준편차를 계산하여, 모든 feature의 평균이 0, 분산이 1이 되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.7937868237814676\n",
      "Accuracy of svm.SVC classifier on test set: 0.8308351177730193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       212\n",
      "           1       0.18      1.00      0.30        42\n",
      "           2       0.46      0.38      0.42        69\n",
      "           3       0.52      1.00      0.68        72\n",
      "           4       0.97      0.42      0.58        72\n",
      "\n",
      "    accuracy                           0.37       467\n",
      "   macro avg       0.63      0.56      0.40       467\n",
      "weighted avg       0.77      0.37      0.30       467\n",
      "\n",
      "confusion matrix:\n",
      " [[  3 153  30  25   1]\n",
      " [  0  42   0   0   0]\n",
      " [  0  43  26   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  0   0   0  42  30]]\n"
     ]
    }
   ],
   "source": [
    "# 전처리 파이프라인 추가\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', svm.SVC(decision_function_shape='ovo', class_weight='balanced', random_state=seed))])\n",
    "pipe.fit(X_tr, Y_tr.ravel())\n",
    "\n",
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {pipe.score(X_tr, Y_tr)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {pipe.score(X_te, Y_te)}')\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리 파이프라인을 추가하니 test set 에서 성능이 0.38 에서 0.83 으로 향상되었습니다.\n",
    "- 이는 overfitting이 되지 않고, 모델이 잘 일반화(generalization) 되었다는 증거입니다.\n",
    "\n",
    "\n",
    "- sklearn의 svm에는 다양한 model parameter가 있으며 이를 변경하여 성능이 어떻게 변하는지 확인해 봅시다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sklearn에는 LibLinear와 LibSVM 두 가지의 SVM 구현체가 있습니다.\n",
    "- 우리는 앞서서 LibSVM을 사용한 SVC를 가지고 테스트를 해 보았으며, LibLinear 구현체를 사용한 SVM 모델을 사용해 보겠습니다.\n",
    "- SVC 와 LinearSVC의 가장 큰 차이는 모델을 최적화 하는데 사용하는 Loss function에 있습니다.\n",
    "\n",
    "\n",
    "- LibLinear 구현체를 사용한, LinearSVC를 이용하여 학습을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.LinearSVC() classifier on training set: 0.79\n",
      "Accuracy of svm.LinearSVC() classifier on test set: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.84       212\n",
      "           1       0.91      0.95      0.93        42\n",
      "           2       0.51      0.99      0.67        69\n",
      "           3       0.85      0.99      0.91        72\n",
      "           4       0.93      0.60      0.73        72\n",
      "\n",
      "    accuracy                           0.81       467\n",
      "   macro avg       0.84      0.85      0.82       467\n",
      "weighted avg       0.88      0.81      0.82       467\n",
      "\n",
      "confusion matrix:\n",
      " [[157   4  35  13   3]\n",
      " [  1  40   1   0   0]\n",
      " [  1   0  68   0   0]\n",
      " [  1   0   0  71   0]\n",
      " [  0   0  29   0  43]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC 모델 \n",
    "clf = svm.LinearSVC(max_iter=1000, class_weight='balanced', random_state=seed)\n",
    "clf.fit(X_tr, Y_tr.ravel())\n",
    "print('Accuracy of svm.LinearSVC() classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_tr, Y_tr)))\n",
    "print('Accuracy of svm.LinearSVC() classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_te, Y_te)))\n",
    "\n",
    "#모델의 성능을 confusion matrix로 확인\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training 과 test set의 accuracy가 꽤 높게 나왔으나 model이 converge하지 않는다는 warning이 발생하고 있습니다.\n",
    "- 이는 data normalizaion이 되지 않아서 발생할 가능성이 있습니다.\n",
    "\n",
    "\n",
    "- 앞에서 배운 전처리 알고리즘을 LinearSVC와 파이프라인으로 구성하면 어떻게 되는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.839850026780932\n",
      "Accuracy of svm.SVC classifier on test set: 0.8736616702355461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85       212\n",
      "           1       0.71      1.00      0.83        42\n",
      "           2       0.86      0.88      0.87        69\n",
      "           3       0.83      1.00      0.91        72\n",
      "           4       0.89      1.00      0.94        72\n",
      "\n",
      "    accuracy                           0.87       467\n",
      "   macro avg       0.85      0.93      0.88       467\n",
      "weighted avg       0.89      0.87      0.87       467\n",
      "\n",
      "confusion matrix:\n",
      " [[161  17  10  15   9]\n",
      " [  0  42   0   0   0]\n",
      " [  8   0  61   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  0   0   0   0  72]]\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC에 전처리 파이프라인 추가\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('LinearSVC', svm.LinearSVC(max_iter=10000, class_weight='balanced', random_state=seed))])\n",
    "model = pipe.fit(X_tr, Y_tr.ravel())\n",
    "\n",
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {model.score(X_tr, Y_tr)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {model.score(X_te, Y_te)}')\n",
    "\n",
    "y_pred = model.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion Matrix를 보면 0으로 잘 못 예측을 하는 경우가 있지만, 다른 class로는 예측하지 않는 어느정도 쓸만한 모델이 만들어 졌습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 model bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bagging이란 입력 데이터를 모델 수 만큼 나눈 뒤, 각각 학습하는 방법입니다.\n",
    "- 모델이 predict_proba() 메소드를 지원하는 경우 확률값을 평균하여 예측을 수행합니다. (소프트보팅)\n",
    "- 해당 메소드가 없는 경우 가장 빈도가 높은 클래스 레이블이 예측 결과가 됩니다. (하드보팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('LinearSVC', svm.LinearSVC(max_iter=100000, class_weight='balanced', random_state=seed))])\n",
    "clf = BaggingClassifier(base_estimator=pipe, n_estimators=7)\n",
    "clf = clf.fit(X_tr, Y_tr.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.8634172469201928\n",
      "Accuracy of svm.SVC classifier on test set: 0.8865096359743041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       212\n",
      "           1       0.75      1.00      0.86        42\n",
      "           2       0.85      0.91      0.88        69\n",
      "           3       0.85      0.99      0.91        72\n",
      "           4       0.90      1.00      0.95        72\n",
      "\n",
      "    accuracy                           0.89       467\n",
      "   macro avg       0.86      0.94      0.89       467\n",
      "weighted avg       0.90      0.89      0.89       467\n",
      "\n",
      "confusion matrix:\n",
      " [[166  14  11  13   8]\n",
      " [  0  42   0   0   0]\n",
      " [  6   0  63   0   0]\n",
      " [  1   0   0  71   0]\n",
      " [  0   0   0   0  72]]\n"
     ]
    }
   ],
   "source": [
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {clf.score(X_tr, Y_tr)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {clf.score(X_te, Y_te)}')\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도가 87%에서 88%로 1% 좋아졌습니다.\n",
    "- Model Bagging은 모델을 성능을 높일 수 있는 좋은 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 의사결정나무(decision Tree)는 스무고개 게임처럼 연속된 질문을 통해서 클래스를 분류하는 방법입니다.\n",
    "- 데이터를 가지고 알고리즘이 최적의 스무고개 질문을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set : 1.0\n",
      "accuracy on test set : 0.9892933618843683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       212\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       0.99      1.00      0.99        69\n",
      "           3       1.00      1.00      1.00        72\n",
      "           4       0.99      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.99       467\n",
      "   macro avg       0.98      0.99      0.99       467\n",
      "weighted avg       0.99      0.99      0.99       467\n",
      "\n",
      "confusion matrix:\n",
      " [[208   2   1   0   1]\n",
      " [  0  42   0   0   0]\n",
      " [  0   0  69   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  1   0   0   0  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=seed)\n",
    "clf = clf.fit(X_tr, Y_tr)\n",
    "\n",
    "print(f\"accuracy on training set : {clf.score(X_tr, Y_tr)}\")\n",
    "print(f\"accuracy on test set : {clf.score(X_te, Y_te)}\")\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test set의 accuracy가 0.98이 나왔습니다.\n",
    "- 데이터 셋의 개수가 적어서 Decision Tree 알고리즘이 좋은 성능을 보여 주고 있습니다.\n",
    "\n",
    "\n",
    "- Decision Tree의 depth가 깊어질수록 결정 경계(decision boundary)가 더 복잡해 질 수 있습니다.\n",
    "- Decison Boundary가 복잡해지면 과적합(overfitting)이 발생 할 수 있는 가능성이 높아집니다.\n",
    "- depth를 조절하면서 prediction  성능이 어떻게 변하는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 1,  accuracy on test set : 0.5674518201284796, accuracy on training set : 0.5704338510980183\n",
      "depth 2,  accuracy on test set : 0.6638115631691649, accuracy on training set : 0.6845206213176218\n",
      "depth 3,  accuracy on test set : 0.7944325481798715, accuracy on training set : 0.7975361542581682\n",
      "depth 4,  accuracy on test set : 0.8501070663811563, accuracy on training set : 0.8393144081414033\n",
      "depth 5,  accuracy on test set : 0.9250535331905781, accuracy on training set : 0.9282271023031602\n",
      "depth 6,  accuracy on test set : 0.9850107066381156, accuracy on training set : 0.9855382967327263\n",
      "depth 7,  accuracy on test set : 0.9935760171306209, accuracy on training set : 0.9930369576861274\n",
      "depth 8,  accuracy on test set : 0.9935760171306209, accuracy on training set : 0.998393144081414\n",
      "depth 9,  accuracy on test set : 0.9957173447537473, accuracy on training set : 0.9989287627209427\n",
      "depth 10,  accuracy on test set : 0.9892933618843683, accuracy on training set : 1.0\n",
      "depth 11,  accuracy on test set : 0.9892933618843683, accuracy on training set : 1.0\n",
      "depth 12,  accuracy on test set : 0.9892933618843683, accuracy on training set : 1.0\n",
      "depth 13,  accuracy on test set : 0.9892933618843683, accuracy on training set : 1.0\n",
      "depth 14,  accuracy on test set : 0.9892933618843683, accuracy on training set : 1.0\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,15):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth, random_state=seed)\n",
    "    clf = clf.fit(X_tr, Y_tr)\n",
    "    print(f\"depth {depth},  accuracy on test set : {clf.score(X_te, Y_te)}, accuracy on training set : {clf.score(X_tr, Y_tr)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Depth가 깊어지면서 성능이 향상되고 있습니다.\n",
    "- 적당한 depth=6 를 가지고 다시 학습해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set : 0.9855382967327263\n",
      "accuracy on test set : 0.9850107066381156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       212\n",
      "           1       1.00      0.98      0.99        42\n",
      "           2       1.00      1.00      1.00        69\n",
      "           3       1.00      1.00      1.00        72\n",
      "           4       0.99      0.93      0.96        72\n",
      "\n",
      "    accuracy                           0.99       467\n",
      "   macro avg       0.99      0.98      0.99       467\n",
      "weighted avg       0.99      0.99      0.98       467\n",
      "\n",
      "confusion matrix:\n",
      " [[211   0   0   0   1]\n",
      " [  1  41   0   0   0]\n",
      " [  0   0  69   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  5   0   0   0  67]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=6, random_state=seed)\n",
    "clf = clf.fit(X_tr, Y_tr)\n",
    "\n",
    "print(f\"accuracy on training set : {clf.score(X_tr, Y_tr)}\")\n",
    "print(f\"accuracy on test set : {clf.score(X_te, Y_te)}\")\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 본 샘플 데이터 셋에서는 거의 완벽한 모델이라고 할 수 있습니다.\n",
    "\n",
    "\n",
    "- 이번에는 Tree split 조건을 결정할 때 사용하는 loss function을 변경하여 보겠습니다.\n",
    "\n",
    "- Sklearn의 Decision Tree는 loss function으로 \"Gini impurity\"를 기본으로 사용합니다.\n",
    "\n",
    "- Decision Tree의 loss fuction을 “entropy\"로 변경하여 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set : 0.9330476700589181\n",
      "accuracy on test set : 0.9336188436830836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       212\n",
      "           1       1.00      1.00      1.00        42\n",
      "           2       0.69      1.00      0.82        69\n",
      "           3       1.00      1.00      1.00        72\n",
      "           4       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           0.93       467\n",
      "   macro avg       0.94      0.97      0.95       467\n",
      "weighted avg       0.95      0.93      0.94       467\n",
      "\n",
      "confusion matrix:\n",
      " [[181   0  31   0   0]\n",
      " [  0  42   0   0   0]\n",
      " [  0   0  69   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  0   0   0   0  72]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=seed)\n",
    "clf = clf.fit(X_tr, Y_tr)\n",
    "\n",
    "print(f\"accuracy on training set : {clf.score(X_tr, Y_tr)}\")\n",
    "print(f\"accuracy on test set : {clf.score(X_te, Y_te)}\")\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class 2와 0을 제외한 모든 데이터를 맞추었습니다.\n",
    "- 이 데이터 셋은 SVM보다 Decision Tree가 더 적합한 ML 모델인 것 같습니다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cross validation (교차검증)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과적합이 발생하면 일반적으로 Traning Set과 Test Set의 성능이 차이가 발생하게 됩니다.\n",
    "- 그러나 적은 데이터 셋에서는 그 차이가 보이지 않는 경우도 있습니다.\n",
    "\n",
    "- 샘플이 적을 경우, 교차검증 (Cross Validation)을 수행하여 그 성능이 차이가 있는지 확인하는 방법도 있습니다.\n",
    "- 지정한 횟수만큼 주어진 데이터를 샘플링하여 모델의 성능을 평가합니다.\n",
    "\n",
    "- 이번에는 9번 반복 검증을 진행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92307692 0.91153846 0.98076923 0.92664093 0.92277992 0.91119691\n",
      " 0.96911197 0.91119691 0.9034749 ]\n",
      "max:  0.9807692307692307 min: 0.9034749034749034\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 셋에 대해서 cross validation을 해보자.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "val_score = cross_val_score(clf, Xs.values, Ys.values.ravel(), cv=9)\n",
    "print(val_score)\n",
    "print(\"max: \", val_score.max(), \"min:\", val_score.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 9번 Cross validation 결과를 보면 최대와 최소 accuracy가 8% 정도 차이가 발생합니다.\n",
    "- 이는 학습한 모델이 과적합이 되었다는 증거가 될 수 있습니다.\n",
    "\n",
    "\n",
    "- 더 많은 데이터셋을 사용하여, 모델의 성능이 어떻게 변하는지 확인하는 것도 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Random Forest\n",
    "\n",
    "\n",
    "- Random Forest는 여러개의 Decision Tree를 만들어서 이를 앙상블(Ensemble)하는 알고리즘 입니다.\n",
    "- 이는 Decision Tree에 비하여 RandomForest가 overfitting에 더 강인한 특징을 가지게 하는 특성이 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set : 0.9892876272094269\n",
      "accuracy on test set : 0.9957173447537473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       212\n",
      "           1       1.00      0.98      0.99        42\n",
      "           2       1.00      0.99      0.99        69\n",
      "           3       1.00      1.00      1.00        72\n",
      "           4       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           1.00       467\n",
      "   macro avg       1.00      0.99      1.00       467\n",
      "weighted avg       1.00      1.00      1.00       467\n",
      "\n",
      "confusion matrix:\n",
      " [[212   0   0   0   0]\n",
      " [  1  41   0   0   0]\n",
      " [  1   0  68   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [  0   0   0   0  72]]\n"
     ]
    }
   ],
   "source": [
    "#random forest 모델\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the model\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=seed)\n",
    "# fit the model\n",
    "clf = clf.fit(X_tr, Y_tr.ravel())\n",
    "\n",
    "print(f\"accuracy on training set : {clf.score(X_tr, Y_tr)}\")\n",
    "print(f\"accuracy on test set : {clf.score(X_te, Y_te)}\")\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(metrics.classification_report(Y_te, y_pred, labels=np.unique(y_pred)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest는 여러개의 Decision Tree를 사용하는 boosting algorithm이기 때문에 동일한 depth를 사용하면 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96153846 0.98846154 0.96923077 0.98069498 0.96911197 0.98069498\n",
      " 0.98841699 0.98455598 0.97683398]\n",
      "max:  0.9884615384615385 min: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 셋에 대해서 cross validation을 해보자.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "val_score = cross_val_score(clf, Xs.values, Ys.values.ravel(), cv=9)\n",
    "print(val_score)\n",
    "print(\"max: \", val_score.max(), \"min:\", val_score.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Randomforest를 교차검증을 해보면 96%에서 98%까지 그 성능의 편차가 Decision Tree에 비하여 크지 않은  것을 볼 수 있습니다.\n",
    "- 이는 Randomforest가 Decision Tree에 비하여 overfitting에 강인하다는 증거입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Feature importance\n",
    "\n",
    "- Random Forest와 Decision Tree와 같은 Tree 기반 알고리즘 내부적으로 Feature의 중요도를 평가 합니다.\n",
    "- Random forest에서 학습한 모델에서 중요도를 추출하여 이를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R_AbsMax' 'S_AbsMax' 'T_AbsMax' 'R_AbsMean' 'S_AbsMean' 'T_AbsMean'\n",
      " 'R_P2P' 'S_P2P' 'T_P2P' 'R_RMS' 'S_RMS' 'T_RMS' 'R_Skewness' 'S_Skewness'\n",
      " 'T_Skewness' 'R_Kurtosis' 'S_Kurtosis' 'T_Kurtosis' 'R_Crest' 'S_Crest'\n",
      " 'T_Crest' 'R_Shape' 'S_Shape' 'T_Shape' 'R_Impulse' 'S_Impulse'\n",
      " 'T_Impulse' 'RS_phase' 'ST_phase' 'TR_phase' 'RS_Level' 'ST_Level'\n",
      " 'TR_Level' 'R_1x' 'S_1x' 'T_1x' 'R_2x' 'S_2x' 'T_2x' 'R_3x' 'S_3x' 'T_3x'\n",
      " 'R_4x' 'S_4x' 'T_4x' 'WATT']\n",
      "[ 9 11  3  4 10  6  1  5  7  0 21 32 31 17 22  2 38 23 30 24 37 36 16 19\n",
      " 20 33  8 27 25 34 35 18 26 14 12 40 43 15 41 45 42 44 13 39 28 29]\n",
      "0 \t columns: R_RMS, \timportance: 0.07800926170442296\n",
      "1 \t columns: T_RMS, \timportance: 0.07030654474376895\n",
      "2 \t columns: R_AbsMean, \timportance: 0.059700550259374915\n",
      "3 \t columns: S_AbsMean, \timportance: 0.05782513785686225\n",
      "4 \t columns: S_RMS, \timportance: 0.05376437578260215\n",
      "5 \t columns: R_P2P, \timportance: 0.0505267621336441\n",
      "6 \t columns: S_AbsMax, \timportance: 0.04848951876983021\n",
      "7 \t columns: T_AbsMean, \timportance: 0.045363176113877184\n",
      "8 \t columns: S_P2P, \timportance: 0.04527998315133391\n",
      "9 \t columns: R_AbsMax, \timportance: 0.04287559153584595\n",
      "10 \t columns: R_Shape, \timportance: 0.03276054704965679\n",
      "11 \t columns: TR_Level, \timportance: 0.032473860304971465\n",
      "12 \t columns: ST_Level, \timportance: 0.031162711921366403\n",
      "13 \t columns: T_Kurtosis, \timportance: 0.029774864066890717\n",
      "14 \t columns: S_Shape, \timportance: 0.026554510543038555\n",
      "15 \t columns: T_AbsMax, \timportance: 0.02503825000646362\n",
      "16 \t columns: T_2x, \timportance: 0.024135021867329784\n",
      "17 \t columns: T_Shape, \timportance: 0.022967850316066168\n",
      "18 \t columns: RS_Level, \timportance: 0.022309757373524686\n",
      "19 \t columns: R_Impulse, \timportance: 0.017897037008701534\n",
      "20 \t columns: S_2x, \timportance: 0.017444655760527925\n",
      "21 \t columns: R_2x, \timportance: 0.01575703897098342\n",
      "22 \t columns: S_Kurtosis, \timportance: 0.01561871961083973\n",
      "23 \t columns: S_Crest, \timportance: 0.014478723189556278\n",
      "24 \t columns: T_Crest, \timportance: 0.012660041568166476\n",
      "25 \t columns: R_1x, \timportance: 0.012567795651186892\n",
      "26 \t columns: T_P2P, \timportance: 0.012282876060132517\n",
      "27 \t columns: RS_phase, \timportance: 0.011885508087355993\n",
      "28 \t columns: S_Impulse, \timportance: 0.01060155951014099\n",
      "29 \t columns: S_1x, \timportance: 0.010094239242766223\n",
      "30 \t columns: T_1x, \timportance: 0.009444677698681304\n",
      "31 \t columns: R_Crest, \timportance: 0.008918732015172862\n",
      "32 \t columns: T_Impulse, \timportance: 0.005775249530052725\n",
      "33 \t columns: T_Skewness, \timportance: 0.004834061432245986\n",
      "34 \t columns: R_Skewness, \timportance: 0.00413229483031785\n",
      "35 \t columns: S_3x, \timportance: 0.004081990745739213\n",
      "36 \t columns: S_4x, \timportance: 0.0034398997459666207\n",
      "37 \t columns: R_Kurtosis, \timportance: 0.003099231165235722\n",
      "38 \t columns: T_3x, \timportance: 0.0024172700121049056\n",
      "39 \t columns: WATT, \timportance: 0.001043864206754081\n",
      "40 \t columns: R_4x, \timportance: 0.0009123951771526338\n",
      "41 \t columns: T_4x, \timportance: 0.0009028552003089432\n",
      "42 \t columns: S_Skewness, \timportance: 0.0002027710258331257\n",
      "43 \t columns: R_3x, \timportance: 0.00017628990184121915\n",
      "44 \t columns: ST_phase, \timportance: 1.1947151364088231e-05\n",
      "45 \t columns: TR_phase, \timportance: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Random forest 모델에서 계산한 각 Feature의 중요도를 복사\n",
    "importance = clf.feature_importances_\n",
    "col_names = Xs.columns.values\n",
    "\n",
    "# 중요도가 높은 순서대로 index를 정렬하여 값을 print\n",
    "indices = np.argsort(importance)[::-1]\n",
    "print(col_names)\n",
    "print(indices)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i} \\t columns: {col_names[idx]}, \\timportance: {importance[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1.0\n",
      "46 0.021739130434782608 19 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature Importances\")\n",
    "\n",
    "plt.bar(range(X_tr.shape[1]), importance[indices], color='lightblue', align='center')\n",
    "plt.xticks(range(X_tr.shape[1]), col_names[indices], rotation=90)\n",
    "plt.xlim([-1, X_tr.shape[1]])\n",
    "plt.tight_layout()\n",
    "\n",
    "print((importance > 0.05).sum(), importance.sum())\n",
    "print(len(importance),  1/len(importance), (importance > 1/len(importance)).sum(), importance.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요도의 합은 1이기 때문에 46개의 Feature가 모두 동일한 중요도를 가진다면 0.021 (1/46)의 값을 가질 것입니다.\n",
    "- 그러나 평균적인 중요도(0.021) 보다 높은 Feature는 19개입니다.\n",
    "\n",
    "\n",
    "- 중요도가 높은 Feature만을 모아서 SVM에 적용하면 결과가 어떨지 확인해 보는 것도 재미 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퀴즈\n",
    "\n",
    "2.4에서 Random forest 모델을 바탕으로 구한 `importance`를 기반으로 평균적인 중요도(0.021) 보다 높은 Feature 19개를 사용한 svm 모델을 구현해봅시다.\n",
    "\n",
    "아래 코드에서 평균적인 중요도(0.021) 보다 높은 Feature 19 개로 구성된 데이터프레임을 구하고 `Xs_important`에 저장합니다.\n",
    "\n",
    "5번째 줄의 `None`에 적절한 코드를 넣어 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm.SVC classifier on training set: 0.7595072308516336\n",
      "Accuracy of svm.SVC classifier on test set: 0.7730192719486081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76       212\n",
      "           1       0.68      0.98      0.80        42\n",
      "           2       0.84      0.46      0.60        69\n",
      "           3       0.83      1.00      0.91        72\n",
      "           4       0.87      0.72      0.79        72\n",
      "\n",
      "    accuracy                           0.77       467\n",
      "   macro avg       0.79      0.79      0.77       467\n",
      "weighted avg       0.78      0.77      0.76       467\n",
      "\n",
      "confusion matrix:\n",
      " [[164  19   6  15   8]\n",
      " [  1  41   0   0   0]\n",
      " [ 37   0  32   0   0]\n",
      " [  0   0   0  72   0]\n",
      " [ 20   0   0   0  52]]\n"
     ]
    }
   ],
   "source": [
    "# 중요도가 높은 Feature만을 저장\n",
    "important_col_names = [name for i,name in enumerate(col_names) if importance[i]> 1/len(importance) ]\n",
    "\n",
    "# importan_col_names에 해당되는 Feature들만 선택한 Xs_importa 데이터프레임 저장\n",
    "Xs_important = Xs[important_col_names]\n",
    "\n",
    "# 데이터 분리\n",
    "X_tr_important, X_te_important, Y_tr_important, Y_te_important = train_test_split(Xs_important.values, Ys.values, test_size=test_size, random_state=seed)\n",
    "\n",
    "# LinearSVC에 전처리 파이프라인 추가\n",
    "pipe_important = Pipeline([('scaler', StandardScaler()), ('LinearSVC', svm.LinearSVC(max_iter=10000, class_weight='balanced'))])\n",
    "model_important = pipe_important.fit(X_tr_important, Y_tr_important.ravel())\n",
    "\n",
    "#모델의 학습 성능 평가\n",
    "print(f'Accuracy of svm.SVC classifier on training set: {model_important.score(X_tr_important, Y_tr_important)}')\n",
    "print(f'Accuracy of svm.SVC classifier on test set: {model_important.score(X_te_important, Y_te_important)}')\n",
    "\n",
    "y_pred_important = model_important.predict(X_te_important)\n",
    "print(metrics.classification_report(Y_te_important, y_pred_important, labels=np.unique(y_pred_important)))\n",
    "print(\"confusion matrix:\\n\", metrics.confusion_matrix(Y_te_important, y_pred_important))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출하기\n",
    "\n",
    "퀴즈 수행 후, 아래 코드를 실행하면 `Xs_important` 변수가 저장된 `submission.pickle` 파일을 제작하여 채점을 받을 수 있습니다.\n",
    "\n",
    "**아래 코드를 수정하면 채점이 불가능 합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "d = {'quiz': Xs_important.values}\n",
    "\n",
    "with open('submission.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점을 수행하기 위하여 로그인\n",
    "import sys\n",
    "sys.path.append('vendor')\n",
    "from elice_challenge import check_score, upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 업로드\n",
    "await upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점 수행\n",
    "await check_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
